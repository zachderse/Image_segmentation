{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f078cee8-0b46-4777-8a71-f78b7c3d2d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "from os import listdir\n",
    "from os.path import splitext, isfile, join\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch import optim\n",
    "\n",
    "\n",
    "class BasicDataset(Dataset):\n",
    "    def __init__(self, images_dir, mask_dir):\n",
    "        self.images_dir = Path(images_dir)\n",
    "        self.mask_dir = Path(mask_dir)\n",
    "       \n",
    "\n",
    "        self.ids = [splitext(file)[0] for file in listdir(images_dir) if isfile(join(images_dir, file)) and not file.startswith('.')]\n",
    "        \n",
    "        if not self.ids:\n",
    "            raise RuntimeError(f'No input file found in {images_dir}, make sure you put your images there')\n",
    "     \n",
    "    \n",
    "    #change preprocess depending on how much tranformations you want\n",
    "    def img_preprocess(self, image):\n",
    "\n",
    "        image = np.asarray(image)\n",
    "        return image\n",
    "        \n",
    "    def mask_preprocess(self, mask):\n",
    "\n",
    "        mask = np.asarray(mask)\n",
    "        return mask\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #name from idx e.g. [0]\n",
    "        name = self.ids[idx]\n",
    "        \n",
    "        \n",
    "        #the one mask file from the given idx\n",
    "        mask_file = list(self.mask_dir.glob(name  + '.*'))\n",
    "        #same but for img_file\n",
    "        img_file = list(self.images_dir.glob(name + '.*'))\n",
    "\n",
    "        #makes the file an image\n",
    "        mask = load_image(mask_file[0])\n",
    "        img = load_image(img_file[0])\n",
    "\n",
    " \n",
    "        img = self.img_preprocess(img)\n",
    "        mask = self.mask_preprocess(mask)\n",
    "\n",
    "        return {\n",
    "            'image': torch.as_tensor(img.copy()).float().contiguous(),\n",
    "            'mask': torch.as_tensor(mask.copy()).long().contiguous()\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "\n",
    "#creating the dataset\n",
    "dataset = BasicDataset(\"...\",\n",
    "                     \"...\"\n",
    "                    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
